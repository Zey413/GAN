{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nkeras.__version__","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"'2.4.3'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In particular, it leverages a Conv2DTranspose layer for image upsampling in the generator.\n#一维张量变为二维张量，cov的反向\n#it is more alchemy than science: these tricks are really just heuristics, not theory-backed guidelines.\n#更像是炼金术\nimport keras\nfrom keras import layers\nimport numpy as np\n\nlatent_dim = 32\nheight = 32\nwidth = 32\nchannels = 3\n\ngenerator_input = keras.Input(shape=(latent_dim,))\n\n# First, transform the input into a 16x16 128-channels feature map\nx = layers.Dense(128 * 16 * 16)(generator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((16, 16, 128))(x)\n\n# Then, add a convolution layer    （5*5*128+1）256\nx = layers.Conv2D(256, 5, padding='same')(x)  \nx = layers.LeakyReLU()(x)\n\n# Upsample to 32x32\n#kernel size that is divisible by the stride size\nx = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# Few more conv layers\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256, 5, padding='same')(x)\nx = layers.LeakyReLU()(x)\n\n# Produce a 32x32 1-channel feature map\nx = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\ngenerator = keras.models.Model(generator_input, x)\ngenerator.summary()","execution_count":1,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 32768)             1081344   \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 32768)             0         \n_________________________________________________________________\nreshape (Reshape)            (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 16, 16, 256)       819456    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n=================================================================\nTotal params: 6,264,579\nTrainable params: 6,264,579\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator_input = layers.Input(shape=(height, width, channels))\nx = layers.Conv2D(128, 3)(discriminator_input)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128, 4, strides=2)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Flatten()(x)\n\n# One dropout layer - important trick!\nx = layers.Dropout(0.4)(x)\n\n# Classification layer\nx = layers.Dense(1, activation='sigmoid')(x)\n\ndiscriminator = keras.models.Model(discriminator_input, x)\ndiscriminator.summary()\n\n# To stabilize training, we use learning rate decay\n# and gradient clipping (by value) in the optimizer.\ndiscriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\ndiscriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set discriminator weights to non-trainable\n# (will only apply to the `gan` model)\ndiscriminator.trainable = False\n\ngan_input = keras.Input(shape=(latent_dim,))\ngan_output = discriminator(generator(gan_input))\ngan = keras.models.Model(gan_input, gan_output)\n\ngan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom keras.preprocessing import image\n\n# Load CIFAR10 data\n(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n\n# Select frog images (class 6)\nx_train = x_train[y_train.flatten() == 6]\n\n# Normalize data\nx_train = x_train.reshape(\n    (x_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n\niterations = 10000\nbatch_size = 20\nsave_dir = '/home/ubuntu/gan_images/'\n\n# Start training loop\nstart = 0\nfor step in range(iterations):\n    # Sample random points in the latent space\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # Decode them to fake images\n    generated_images = generator.predict(random_latent_vectors)\n\n    # Combine them with real images\n    stop = start + batch_size\n    real_images = x_train[start: stop]\n    combined_images = np.concatenate([generated_images, real_images])\n\n    # Assemble labels discriminating real from fake images\n    labels = np.concatenate([np.ones((batch_size, 1)),\n                             np.zeros((batch_size, 1))])\n    # Add random noise to the labels - important trick!\n    labels += 0.05 * np.random.random(labels.shape)\n\n    # Train the discriminator\n    d_loss = discriminator.train_on_batch(combined_images, labels)\n\n    # sample random points in the latent space\n    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n\n    # Assemble labels that say \"all real images\"\n    misleading_targets = np.zeros((batch_size, 1))\n\n    # Train the generator (via the gan model,\n    # where the discriminator weights are frozen)\n    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n    \n    start += batch_size\n    if start > len(x_train) - batch_size:\n      start = 0\n\n    # Occasionally save / plot\n    if step % 100 == 0:\n        # Save model weights\n        gan.save_weights('gan.h5')\n\n        # Print metrics\n        print('discriminator loss at step %s: %s' % (step, d_loss))\n        print('adversarial loss at step %s: %s' % (step, a_loss))\n\n        # Save one generated image\n        img = image.array_to_img(generated_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n\n        # Save one real image, for comparison\n        img = image.array_to_img(real_images[0] * 255., scale=False)\n        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Sample random points in the latent space\nrandom_latent_vectors = np.random.normal(size=(10, latent_dim))\n\n# Decode them to fake images\ngenerated_images = generator.predict(random_latent_vectors)\n\nfor i in range(generated_images.shape[0]):\n    img = image.array_to_img(generated_images[i] * 255., scale=False)\n    plt.figure()\n    plt.imshow(img)\n    \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}